# 计算机网络
# 内容
### 1、OSI七层模型和TCP/IP四层模型

- TCP/IP四层模型

	1.链路层（数据链路层/网络接口层）：包括操作系统中的设备驱动程序、计算机中对应的网络接口卡

	2.网络层（互联网层）：处理分组在网络中的活动，比如分组的选路。网络层IP提供的是一种不可靠的服务。它只是尽可能快地把分组从源节点送到目的节点，但不提供任何可靠性的保证。
	
	3.运输层：主要为两台主机上的应用提供端到端的通信。Tcp在不可靠的ip层上，提供了一个可靠的运输层，为了提供这种可靠的服务，TCP采用了超时重传、发送和接受端到端的确认分组等机制。
	
	4.应用层：负责处理特定的应用程序细节。主要有HTTP和文件传输的FTP服务

- OSI七层模型

	 - 1、物理层：
		
		主要功能：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。
		
		作用：实现相邻计算机节点之间比特流的透明传输，尽可能屏蔽掉具体传输介质与物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。
		
		透明传输的意义就是：不管传的是什么，所采用的设备只是起一个通道作用，把要传输的内容完好的传到对方！
	
	- 2、数据链路层：负责建立和管理节点间的链路。

		主要功能：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。

		具体工作：接受来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上一层的数据帧，拆装为位流形式的数据转发到物理层；并且还负责处理接受端发回的确认帧的信息，以便提供可靠的数据传输。

		该层通常又被分为 介质访问控制(MAC)和逻辑链路控制(LLC)两个子层：
			 
		- MAC子层的主要任务是解决共享型网络中多用户对信道竞争的问题，完成网络介质的访问控制。
			 
		- LLC子层的主要任务是建立和维护网络连接，执行差错校验、流量控制和链路控制。
 
	 - 3、网络层：是OSI参考模型中最复杂的一层，也是通信子网最高的一层，它在下两层的基础上向资源子网提供服务。

		主要任务：通过路由算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与物理层之间的信息转发，建立、维持与终止网络的连接。具体的说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。一般的，数据链路层是解决统一网络内节点之间的通信，而网络层主要解决不同子网之间的通信。例如路由选择问题。

		在实现网络层功能时，需要解决的主要问题如下：

		- 寻址：数据链路层中使用的物理地址（如MAC地址）仅解决网络内部的寻址问题。在不同子网之间通信时，为了识别和找到网络中的设备，每一子网中的设备都会被分配一 个唯一的地址。由于各个子网使用的物理技术可能不同，因此这个地址应当是逻辑地址（如IP地址）

		- 交换：规定不同的交换方式。常见的交换技术有：线路交换技术和存储转发技术，后者包括报文转发技术和分组转发技术。

		- 路由算法：当源节点和路由节点之间存在多条路径时，本层可以根据路由算法，通过网络为数据分组选择最佳路径，并将信息从最合适的路径，由发送端传送的接受端。

		- 连接服务：与数据链路层的流量控制不同的是，前者控制的是网络相邻节点间的流量，后者控制的是从源节点到目的节点间的流量。其目的在于防止阻塞，并进行差错检测。

	 - 4、传输层：

    OSI的下三层的主要任务是数据传输，上三层的主要任务是数据处理。而传输层是第四层，因此该层是通信子网和资源子网的接口和桥梁，起到承上启下的作用。

	主要任务：向用户提供可靠的、端到端的差错和流量控制，保证报文的正确传输。
	
	主要作用：向高层屏蔽下层数据通信的具体细节，即向用户透明的传送报文。

	传输层提供会话层和网络层之间的传输服务，这种服务从会话层获得数据，并在必要时，对数据进行分割，然后，传输层将数据传送到网络层，并确保数据能准确无误的传送到网络层。因此，传输层负责提供两节点之间数据的可靠传送，当两节点的联系确定之后，传输层负责监督工作。综上，传输层的主要功能如下：
 
 	传输连接管理：提供建立、连接和拆除传输连接的功能。传输层在网络层的基础上，提供“面向连接”和“面向无连接”两种服务

	处理传输差错：提供可靠的“面向连接”和不可靠的“面向无连接”的数据传输服务、差错控制和流量控制。在提供“面向连接”服务时，通过这一层传输的数据将由目标设备确认，  如果在指定的时间内未收到确认信息，数据将被重新发送。监控服务质量 

	- 5、会话层：是OSI参考模型的第五层，是用户应用程序和网络之间的接口
	
	主要任务：向两个实体的表示层提供建立和使用连接的方法。将不同实体之间的表示层的连接称为会话。因此会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。
		
	用户可以按照半双工、单工和全工的方式建立会话。当建立会话时，用户必须提供他们想要连接的远程地址。而这些地址与MAC（介质访问控制子层）地址或网络层的逻辑地址不同，他们是为用户专门设计的，更便于用户记忆。域名(DN)就是网络上使用的远程地址。会话层的具体功能如下：
		
	 - 会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。例如提供单方向会话或双向同时会话，并管理会话中的发送顺序，以及会话所占用时间的长短。
		
		- 会话流量控制：提供流量控制和交叉会话功能。
		
		- 寻址：使用远程地址建立会话连接。

		- 出错控制：从逻辑上讲，会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠错。会话控制和远程过程调用均属于这一层的功能。但应注意，此层检查的错误不是通信介质的错误，而是磁盘空间、打印机缺纸等高级类的错误。
 
	- 6、表示层：

	- 表示层是OSI模型的第六层，它对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。

        - 其主要功能是“处理用户信息的表示问题，如编码、数据格式转换和加密解密”等。

		表示层的具体功能如下：

		- 数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。

		- 数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。

			压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。

			数据的加密和解密：可以提高网络的安全性。
	- 7、应用层

		- 应用层是OSI参考模型的最高层，它是计算机用户，以及各种应用程序和网络之间的接口。

		- 主要功能：直接向用户提供服务，完成用户希望在网络上完成的各种工作。它在其他6层工作的基础上，负责完成网络中应用程序与网络操作系统之间的联系，建立与结束使用者之间的联系，并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外，该层还负责协调各个应用程序间的工作。

		- 应用层为用户提供的服务和协议有：文件服务、目录服务、文件传输服务（FTP）、远程登录服务（Telnet）、电子邮件服务（E-mail）、打印服务、安全服务、网络管理服务、数据库服务等。上述的各种网络服务由该层的不同应用协议和程序完成，不同的网络操作系统之间在功能、界面、实现技术、对硬件的支持、安全可靠性以及具有的各种应用程序接口等各个方面的差异是很大的。应用层的主要功能如下：

		- 用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。

		- 实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。
 
- OSI 7层模型的小结
	由于OSI是一个理想的模型，因此一般网络系统只涉及其中的几层，很少有系统能够具有所有的7层，并完全遵循它的规定。

	在7层模型中，每一层都提供一个特殊的网络功能。从网络功能的角度观察：下面4层（物理层、数据链路层、网络层和传输层）主要提供数据传输和交换功能，即以节点到节点之间的通信为主；第4层作为上下两部分的桥梁，是整个网络体系结构中最关键的部分；而上3层（会话层、表示层和应用层）则以提供用户与应用程序之间的信息和数据处理功能为主。简言之，下4层主要完成通信子网的功能，上3层主要完成资源子网的功能。


### 2、一次完整的http请求的七个过程

- 1、建立tcp数据连接
	
	在HTTP工作开始前，web浏览器向服务器发起连接请求，并建立建立。http协议是比tcp协议更高层次的应用层协议，根据规则，只有低层的协议建立连接才能进行数据通信。因此首先需要建立tcp连接，tcp连接的端口号一般是80.

- 2、web浏览器向web服务器发起请求

	【请求行： 请求方法 、 url 、 协议版本】
	
	一旦建立起连接，浏览器就会立即向服务器发起请求

- 3、web浏览器向web服务器发送头部信息
	
	浏览器向服务器发送他的头部信息，头部信息的格式为name=value的格式发送，最后将以一个空行来告诉服务器发送的请求消息报头已经发送完毕。

- 4、web服务器应答
	
	【状态行：协议版本号 、 应答状态码】
	
	浏览器向服务器发送请求以后，服务器会做出应答，如HTTP/1.1 200 OK

- 5、web服务器向web浏览器发送自己的头部信息
	
	就像客户端向服务器发送自己的头部消息一样，服务器也向客户端发送自己的数据和请求的文档，并以一个空行表示头部信息已经全部发送完毕

- 6.web服务器向浏览器发送数据

	这时候web服务器会以Content-Type应答头部信息所描述的格式发送用户所请求的实际数据

- 7.服务器关闭TCP连接

	一旦web服务器向客户端发送了请求数据，服务器就要断开tcp连接。

	如果浏览器或是服务器的头部信息中加入了“Content-Type：keep-alive”，那么在TCP连接在发送数据之后还是保持着打开状态，浏览器还是可以向服务器发送请求。保持连接节省了为每个请求建立新的连接所需要的时间，还节约了网络带宽。

### 2、keepalive TCP的keepalive和HTTP的keepalive区别

- TCP的keepalive

	通信双方建立交互链接，有的链接会在数据交互完毕之后主动释放链接，但是有的链接却不会，他会保持着链接，那么在长时间没有数据交互的过程中，它是一直链接的，因此通讯双方都有可能会出现掉电、关机、异常重启等意外，当这些意外发生之后，通信的对端可能还并不知道对方的情况，所以他会一直维护着这个链接，那么长时间的积累，可能会产生大量的半打开链接，从而造成了资源的浪费和消耗，所以为了解决这个问题在传输层利用保活报文来实现。
它的作用就是检测对端通信是否还存在

- HTTP的keepalive

	它是提供了keep-alive timeout时间设置参数。这个参数就意味着在TCP链接传出完毕最后一个报文后，经过keepalive_timeout秒后才关闭这个链接，如果守护进程（服务器设置成守护进程）在这个等待的时间内，一直没有收到浏览器发送过来的http请求，则关闭这个链接

- 区别：
	这两个keepalive是不一样的，http的是为了让TCP活的更久一点，以便让同一个链接上传输多个http，以提高socket的效率，而tcp的keepalive是TCP的一种检测TCP链接状况的保鲜机制。

- TCP链接默认的闲置时间是两个小时

- keep-alive与TIME_WAIT
	
	使用http keep-alvie，可以减少服务端TIME_WAIT数量(因为由服务端httpd守护进程主动关闭连接)。道理很简单，相较而言，启用keep-alive，建立的tcp连接更少了，自然要被关闭的tcp连接也相应更少了。

相关资料：http://www.cnblogs.com/hukey/p/5481173.html

### 3、一致性哈希算法是什么

补充资料：
	
  https://www.cnblogs.com/lpfuture/p/5796398.html
	
  http://blog.csdn.net/sparkliang/article/details/5279393

  一致性哈希算法主要用在分布式系统中，为了解决因特网的热点问题。如果有N太服务器和一个对象，此时需要把这个对象与服务器进行匹配，如果是简单的哈希算法进行匹配，此时如果其中一台服务器坏掉了，那么此时的哈希函数可能就变成了hash(object)%(N-1)，这样就会产生一个灾难，这意味着所有的服务器都失效了，因此我们便引入了一致性哈希算法
	
  首先一致性哈希算法的基本思想就是将对象和服务器都映射到同一个 hash 数值空间中，并且使用相同的 hash 算法。如果此时服务器连起来是一个环状，那么对象的分布就是按照顺时针的方向分布在最近的一个服务器上，这样如果后续有的服务器挂掉了那么我们只需要更改这个区间内的对象分布即可，不需要更改后续和前面的对象，同时加对象的时候也调整对象的很少，使对象的分布更加方便。
	
  但是这样也可能会产生一个问题，有可能很多的对象映射到一个服务器上，导致了分配不均衡，所以为了平衡性考虑，我们引进了虚拟节点，虚拟结点也就是一个结点对应了多个结点，这些结点就是虚拟结点，而这些结点也在Hash空间中以Hash值排序，这样映射关系就变成了（对象->结点）到（对象->虚拟结点）这样映射出来的结果会更平衡，这就是一致性哈希算法的思想。
	
### 4、IP分组传输以及重传等

### 5、Select、poll、epoll解析
**（重点，每次面试必问！！）**

**注：此处要讲到现在很多的博客抄过来抄过去，很多都是错误的，在epoll模型中并没有使用内存映射，完全是一种谣言，底层代码根本就没有内存映射（这里参照了知乎用户-奥特曼的文章）**

PS：这个问题写的有点乱。。。补充中

  select、poll、epoll这三组I/O复用系统调用都能同时监听多个文件描述符，他们都通过timeout参数指定要等待的时间。直到事件就绪时返回，返回值就是就绪的文件描述符的数量。

  下面我们从事件集、最大支持文件描述符数量，工作模式和具体实现方面比较一下他们的异同：

- 1、事件集 
	select的参数没有将文件描述符和事件绑定，他仅仅是一个文件描述符的集合，所以select需要分别用三个参数来区分传入的可读，可写及异常事件，这不仅限制了select只能处理这三种事件，另外由于内核对fd_set集合的在线修改，所以下次再调用select之前还需要重置这3个文件描述符集合。 

	poll将文件描述符和事件都定义在pollfd结构体中，使得任何事件都能被统一处理，而且pollfd将监测事件和就绪事件分开了，保证events不被改变，因此pollfd不需要重置pllfd结构中的events成员。但是因为select和poll返回的都是整个事件集合，所以他们查找就绪事件的文件描述符的效率都是O(n)。 

	epoll在内核中维护了一个事件表，而且还提供一个函数epoll_ctl来向事件表中添加、删除、修改事件，所以它无须每次都重置事件。因为epoll返回的都是就绪事件，所以epoll查找就绪事件的文件描述符的时间复杂度都是O(1)。

- 2、最大支持的文件描述符数量 
	
	poll和epoll都能达到系统允许打开的文件描述符的最大值。 
	
	select允许监听的最大文件描述符数量通常有限制，虽然可以修改，但是不建议修改。

- 3、工作模式 

	select和poll都只能处在相对低效的LT模式，而epoll可以处于ET高效模式。

- 4、具体实现 
	
	select和poll采用的都是轮询的方式，每次都要扫描整个事件集合，才能找到就绪事件的文件描述符。而epoll采用的是callback(回调机制)，只要内核检测到就绪事件，就触发回调机制，将就绪事件移到就绪队列中等待用户处理。 


	select的本质是采用32个整数的32位，即32*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE的大小。这个时候就可以标识32*max值范围的fd。


poll传递的是数组头指针和该数组的长度，只要数组的长度不是很长，性能还是很不错的，因为poll一次在内核中申请4K(一个页的大小来存放fd)，尽量控制在4K以内。

epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用户态，然后传递到内核中。但是只有在2.6的内核才支持。

epoll更适合于处理大量的fd ，且活跃fd不是很多的情况，毕竟fd较多还是一个串行的操作

epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射(mmap)技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。

另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。


epoll 虽然网络上很多博客说epoll的高效基于共享内存，但实际上它并没有实现这个共享内存的机制，它底层是实现了一个红黑树，红黑树的结点包括fd和回调函数，红黑树上面是一个就绪队列，保存了以及就绪的文件描述符，此时直接在用户态和内核态复制，并不是基于共享内存机制的。


### 6、epoll中ET和LT的区别（必须非常详尽的解释水平触发和边缘触发的区别，以及边缘触发在编程中要做哪些更多的确认）
- ET工作模式（边缘触发）
	
	当向epoll内核事件表中注册一个文件描述符上的EPOLLET事件的时，epoll将通过ET(边沿模式)来操作该文件描述符，ET模式是epoll的高效工作模式。对于在ET模式工作的文件描述符来说：当epoll_wait检测到其上有事件发生并将此事件通知应用程序后，应用程序应该立即处理该事件，因为后续的epoll_wait调用将不再向应用程序通知这一事件。ET模式在很大程度上降低了同一个epoll事件被重复触发的次数，所以ET要更高效。使用ET模式的文件描述符都应该是非阻塞的，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务都饿死。ET只支持非阻塞方式。

- LT工作模式（默认模式，水平触发）
	
	模式是默认的模式，在这种模式下epoll相当于一个效率较高poll。采用LT的工作模式时:当epoll_wait检测到其上有事件发生并将此事件通知应用程序后，应用程序可以不立即处理该事件。这样，当应用程序下一次调用epoll_wait时，epoll_wait还会再次向应用程序通告此事件，直到事件被处理。LT同时支持阻塞和非阻塞方式。

- 理论上边缘触发的性能要更高一些，但是代码实现相当复杂。

### 7、TCP和UDP的区别（必问！！）王者荣耀比较适合用UDP还是TCP

- TCP是面向链接的，UDP是无链接的.

- TCP提供可靠的服务 UDP尽最大的努力进行交付

- TCP占用资源多，UDP较少资源

- TCP面向字节流， UDP面向数据块

- TCP提供丢包重传 UDP不会

- TCP提供按序到达 UDP不会

- UDP传输速度快于TCP

### 8、Post和get方法请求不同，post内部的实现方法，你还知道什么请求方法？

Get方法获取URI 指定的信息。如果URI 指定的是文件，则返回文件的内容；如果URI 指定的是CGI 程序，则返回该程序的输出数据。

Post方法从客户端向服务器发送数据。一般用于发送表单中填写的数据等情况下

### 9、http协议和https协议的区别

HTTPS使用了HTTP协议，但HTTPS使用不同于HTTP协议的默认端口及一个加密、身份验证层.

客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤。

- （1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。

- （2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。

- （3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。

- （4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。

- （5）Web服务器利用自己的私钥解密出会话密钥。

- （6）Web服务器利用会话密钥加密与客户端之间的通信

	http的连接很简单，是无状态的HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议要比http协议安全
	
	SSL是安全保密协议，在浏览器和Web服务器之间构造安全通道来进行数据传输，SSL运行在TCP/IP层之上、应用层之下，为应用程序提供加密数据通道.

### 10、TCP中的流量控制、滑动窗口、超时重传都讲一下？

- 流量控制：

	接收端处理数据的速度是有限的.如果发送端发的太快,导致接收端的缓冲区被打满,这个时候如果发送端继续发送,就会造成丢包,继而引起丢包重传等等一系列连锁反应.因此TCP支持根据接收端的处理能力,来决定发送端的发送速度.这个机制就叫做流量控制(Flow Control);

	- （1）接收端将自己可以接收的缓冲区大小放入TCP首部中的"窗口大小"字段,通过ACK端通知发送端;

	- （2）窗口小字段越大,说明网络的吞吐量越高;
	
	- （3）接收端一旦发现自己的缓冲区快满了,就会将窗口大小设置成一个更小的值通知给发送端;
	
	- （4）发送端接受到这个窗口之后,就会减慢自己的发送速度;
	
	- （5）如果接收端缓冲区满了,就会将窗口置为0;这时发送方不再发送数据,但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端

- 滑动窗口 (Sliding window)
	
	是一种流量控制技术。滑动窗口协议是用来改善吞吐量的一种技术，即容许发送方在接收任何应答之前传送附加的包。接收方告诉发送方在某一时刻能送多少包(称窗口尺寸)。TCP中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为0时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个1字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。滑动窗口协议的基本原理就是在任意时刻，发送方都维持了一个连续的允许发送的帧的序号，称为发送窗口;同时，接收方也维持了一个连续的允许接收的帧的序号，称为接收窗口。发送窗口和接收窗口的序号的上下界不一定要一样，甚至大小也可以不同。不同的滑动窗口协议窗口大小一般不同。发送方窗口内的序列号代表了那些已经被发送，但是还没有被确认的帧，或者是那些可以被发送的帧。

	窗⼝大小指的是无需等待确认应答而可以继续发送数据的最大值.上图的窗口大小就是4000个字节(四个段).发送前四个段的时候,不需要等待任何ACK,直接发送;收到第一个ACK后,滑动窗口向后移动,继续发送第五个段的数据;依次类推;操作系统内核为了维护这个滑动窗口,需要开辟发送缓冲区来记录当前还有哪些数据没有应答;只有确认应答过的数据,才能从缓冲区删掉;窗口越大,则网络的吞吐率就越高;

	 - 数据包已经抵达, ACK被丢了：无所谓，通过后续的ACK确认报文确认

	 - 数据包直接丢失：不断通知想要什么数据

- 超时重传：
	
	主机A发送数据给主机B之后，可能因为网络阻塞等原因，数据无法到达主机B。

	如果主机A在一个特定的时间间隔内没有收到B发送的确认报文，则会进行重新发送。
	
	因此可能会产重很多重复数据，这个重复数据就通过TCB报文段的序列号来进行一个确认去重。
	
	因此这个时间确认的太长则会影响整个重传的效率，这个时间太短，则会频繁发送数据包，因此这个时间的确认是通过一个动态的时间来计算这个超时时间的。Linux下超时是以500ms为一个单位进行控制，每次判定超时重发的时间是500ms的整数倍，如果重发一次后任然得不到应答，则此时等待2\*500ms后进行重新传送，以此类推，以指数形式递增，一旦当到达一定的重传次数，TCP认为网络或者对端主机出现异常，强制关闭连接。
	
### 11、TCP接收方为什么保证按序接收

如果TCP没有这样烦琐的操作，那么，可能会造成更多的麻烦。如造成数据包的重传、顺序的颠倒甚至造成数据包的丢失。

主机每次发送数据时，TCP就给每个数据包分配一个序列号并且在一个特定的时间内等待接收主机对分配的这个序列号进行确认，如果发送主机在一个特定时间内没有收到接收主机的确认，则发送主机会重传此数据包。接收主机利用序列号对接收的数据进行确认，以便检测对方发送的数据是否有丢失或者乱序等，接收主机一旦收到已经顺序化的数据，它就将这些数据按正确的顺序重组成数据流并传递到高层进行处理。

步骤：

- （1）为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区； 

- （2）并为每个已发送的数据包启动一个超时定时器； 

- （3）如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区; 

- （4）否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。

- （5）接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。

### 12、拥塞控制介绍一下

  一个是慢启动，一个是快重传
	
  慢启动就是先发送少量的数据，进行一个探路的操作，摸清当前网络的拥堵状态，再按照多大的速度进行传输数据，此时通过拥塞窗口进行一个控制。

（发送开始定义拥塞窗口为1，每次收到一个ACK应答，此时拥塞窗口加一，每次发送数据包的时候,将拥塞窗口和接收端主机反馈的窗口大小做比较,取较小的值作为实际发送的窗口）慢启动指的是初始启动慢，但是增长速度非常快。但是一旦超过慢启动的阈（yu）值的时候不再按照指数方式增长，而是按照线性方式增长。

### 13、TCP/IP三次握手四次挥手（必会！！必问）

### 14、TCP四次挥手时的TIME_WAIT和CLOSE_WAIT是什么？2MSL？
通信双方建立TCP连接后，主动关闭连接的一方就会进入TIME_WAIT状态。

- 为什么存在TIME_WAIT状态？
	
	TCP这样设计的两个原因：
	
	- 1. 可靠地实现TCP全双工连接的终止
	
		TCP协议在关闭连接的四次握手过程中，最终的ACK是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK丢失，对方（后面统称B端）将重发出最终的FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误（在java中会抛出connectionreset的SocketException)。

		因而，要实现TCP全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的A端必须维持TIME_WAIT状态 。
	
	- 2. 允许老的重复segment在网络中消逝
		
		TCP segment 可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个segment，迷途的segment在路由器修复后也会被送到最终目的地，这个迟到的迷途segment到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，就可以保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消逝。

- 如果TIME_WAIT维持的时间过长？
	
	主动关闭连接端迟迟无法关闭连接，占用程序资源。

- 如果TIME_WAIT维持的时间过短？

	1 缩短TIME-WAIT的时间后，延迟的TCP 包会被新建立的TCP连接接收。

- 为什么是2MSL
	
	MSL是TCP报⽂文的最⼤大⽣生存时间,因此TIME_WAIT持续存在2MSL的话就能保证在两个传输⽅方向上的尚未被接收或迟到的报⽂文段都已经消失(否则服务器⽴立刻重启,可能会收到来⾃自上⼀一个进程的迟到的数据,但是这种数据很可能是错误的);同时也是在理论上保证最后⼀一个报⽂文可靠到达(假设最后⼀一个ACK丢失,那么服务器会再重发⼀一个FIN.这时虽然客户端的进程不在了,但是TCP连接还在,仍然可以重发LAST_ACK);

- 服务器程序一直保持CLOSE_WAIT状态
	
	如果服务器程序TCP连接一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直 

### 15、TCP为什么三次握手？两次可以吗？四次？
	
  首先要知道三次握手握的是什么，三次握手握的是握的是通讯双方数据源点的序列号！
	
  如果握手两次：就是A和B就A的初始序列号达成了一致，但是B无法知道A是否已经收到了自己的同步信号，如果这个同步信号丢失了，则A和B的初始序列号将无法达成一致。如果此时A发送给B的确认报文丢失了，并不会超时重传ACK报文，因为TCP不会为没有数据的ACK超时重传。所以如果B没有收到A的ACK确认报文，则会超时重传自己的SYN同步信号，直到收到A的ACK确认报文为止。

  如果四次握手:四次握手产生的情况在中间两部完全可以由三次握手中间一步完成，所以四次握手产生了一种资源上的浪费。

### 16、TCP四次挥手过程，若TCP只有三次挥手时会发生什么

- 为什么四次：
	
	三次握手客户端的LISTEN状态下的SOCKET收到SYN报文的连接请求后，它可以把ACK和SYN放在一个报文里来发送。但关闭连接时，当收到对方的FIN通知时，它仅仅表示对方没有数据发送给你，但并不代表你不会给它发送数据，所以你可能不会立即关闭SOCKET，而是发送FIN报文给对方表示你同意现在可以关闭连接了，所以这里的ACK报文和FIN报文多数情况下是分开发送的。

- 三次挥手：
	
	此时收到FIN的一端认为连接结束了，可是另外一端发送端并不确定我发送的FIN对端是否收到。

### 17、TCP如何实现断线重连
	
  因为会进入time_wait状态，所以此时用setsockopt ()函数进行一个设置，可以防止进入time_wait状态导致无法重新连接
	
#### 18、什么情况下会有flood攻击、timewait攻击？
- Flood攻击
	
	假设一个用户向服务器发送了SYN报文后突然死机或掉线，那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的（第三次握手无法完成），这种情况下服务器端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接，这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）但如果有一个恶意的攻击者大量模拟这种情况，服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源----数以万计的半连接，即使是简单的保存并遍历也会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。实际上如果服务器的TCP/IP栈不够强大，最后的结果往往是堆栈溢出崩溃---即使服务器端的系统足够强大，服务器端也将忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYN Flood攻击（SYN洪水攻击）。

- Time_wait攻击：
	
	如果客户端的TIME_WAIT连接过多，同时它还在不断产生，将会导致客户端端口耗尽，新的端口分配不出来，出现错误。如果服务器端的TIME_WAIT连接过多，可能会导致客户端的请求连接失

### 19、QQ使用什么网络协议传输的
	Udp为主TCP为辅的一种设计思路

### 20、HTTP返回码

  - 1xx消息:请求已被接受，需要继续处理。HTTP/1.0协议中没有定义任何1xx状态码。

  - 2xx成功:请求已成功被服务器接收、理解并接受
	
  - 3xx重定向（302类似呼叫转移，呼叫旧的号码会转到新的号码上，也例如从登陆界面跳转到主页）
	
  - 4xx:客户端错误
	
  - 5xx:服务器错误

### 21、socket阻塞会返回的情况，出错有哪几种，如何实现高并发

  https://blog.csdn.net/qifengzou/article/details/23912267
### 22、长连接和短链接

- 长链接短连接本质是什么？

- 长连接和短链接的优缺点：
	
	长连接可以省去建立链接和关闭链接的操作，减少浪费，节约时间，但是太多的长连接又会对服务器造成一定的负担，这个时候就要采取一定的策略：关闭一段时间内没有读写事件发生的长连接
	
	短连接对服务器来说管理相对的简单，存在的链接都是游泳的链接，但是如果一个客户端平凡的请求，那么在TCP建立链接和关闭链接的操作上又会花费很多时间。

### 23、Reactor和proactor区别
	
  Reactor模式采用同步IO，而Proactor采用异步IO。

  在Reactor中，Reactor，即反应堆。Reactor 的一般工作过程是首先在 Reactor中注册（Reactor）感兴趣事件，并在注册时候指定某个已定义的回调函数（callback）；当客户端发送请求时，在 Reactor中会触发刚才注册的事件，并调用对应的处理函数。在这一个处理回调函数中，一般会有数据接收、处理、回复请求等操作

  而在Proactor模式中，借助操作系统的异步读写；异步读写在调用的时候可以传递回调函数或者回送信号，当异步操作完毕，内核会自动调用回调函数或者发送信号。Proactor 就是这么做的，所以很依赖操作系统。

### 24、COOKIE跟SESSION的区别

>PS：这个问题很乱。。。待更改
	
  众所周知，HTTP 是一个无状态协议，所以客户端每次发出请求时，下一次请求无法得知上一次请求所包含的状态数据，如何能把一个用户的状态数据关联起来呢？

  比如在淘宝的某个页面中，你进行了登陆操作。当你跳转到商品页时，服务端如何知道你是已经登陆的状态？

- Cookie
	首先产生了 cookie 这门技术来解决这个问题，cookie 是 http 协议的一部分.Cookie 会帮你在网站上所打的文字或是一些选择，都记录下来。当下次你再光临同一个网站，WEB 服务器会先看看有没有它上次留下的 Cookie 资料，有的话，就会依据 Cookie里的内容来判断使用者，送出特定的网页内容给你。 Cookie 的使用很普遍，许多有提供个人化服务的网站，都是利用 Cookie来辨认使用者，以方便送出使用者量身定做的内容，像是 Web 接口的免费 email 网站，都要用到 Cookie。它的处理分为如下几步：

	- 服务器向客户端发送 cookie。
	
	- 通常使用 HTTP 协议规定的 set-cookie 头操作。
	
	- 规范规定 cookie 的格式为 name = value 格式，且必须包含这部分。
	
	- 浏览器将 cookie 保存。
	
	- 每次请求浏览器都会将 cookie 发向服务器。

其他可选的 cookie 参数会影响将 cookie 发送给服务器端的过程，主要有以下几种：

    1. path：表示 cookie 影响到的路径，匹配该路径才发送这个 cookie。
    
    2。 expires 和 maxAge：告诉浏览器这个 cookie 什么时候过期，expires 是 UTC 格式时间，maxAge 是 cookie 多久后过期的相对时间。当不设置这两个选项时，会产生 session cookie，session cookie 是 transient 的，当用户关闭浏览器时，就被清除。一般用来保存 session 的 session_id。
    
    - secure：当 secure 值为 true 时，cookie 在 HTTP 中是无效，在 HTTPS 中才有效。
    
	- httpOnly：浏览器不允许脚本操作 document.cookie 去更改 cookie。一般情况下都应该设置这个为 true，这样可以避免被 xss 攻击拿到 cookie


- Session
　　
  cookie 虽然很方便，但是使用 cookie 有一个很大的弊端，cookie 中的所有数据在客户端就可以被修改，数据非常容易被伪造，那么一些重要的数据就不能存放在 cookie 中了，而且如果 cookie 中数据字段太多会影响传输效率。为了解决这些问题，就产生了 session，session 中的数据是保留在服务器端的。
　
 session 的运作通过一个 session_id 来进行。session_id 通常是存放在客户端的 cookie 中，比如在 express 中，默认是connect.sid 这个字段，当请求到来时，服务端检查 cookie 中保存的 session_id 并通过这个 session_id 与服务器端的 session data 关联起来，进行数据的保存和修改。
	
  
  这意思就是说，当你浏览一个网页时，服务端随机产生一个 1024 比特长的字符串，然后存在你 cookie 中的 connect.sid字段中。当你下次访问时，cookie 会带有这个字符串，然后浏览器就知道你是上次访问过的某某某，然后从服务器的存储中取出上次记录在你身上的数据。由于字符串是随机产生的，而且位数足够多，所以也不担心有人能够伪造。伪造成功的概率比坐在家里编程时被邻居家的狗突然闯入并咬死的几率还低。
　　
  session 可以存放在 1）内存、2）cookie本身、3）redis 或 memcached 等缓存中，或者4）数据库中。线上来说，缓存的方案比较常见，存数据库的话，查询效率相比前三者都太低，不推荐；cookie session 有安全性问题，

- cookie 和session 的区别：
1、cookie数据存放在客户的浏览器上，session数据放在服务器上。
2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗
   考虑到安全应当使用session。
3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能
   考虑到减轻服务器性能方面，应当使用COOKIE。
4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。
http://www.cnblogs.com/vincently/p/4841897.html

### 25、DNS是什么
  让路由器来使用IP 地址。为了填补两者之间的障碍，需要有一个机制能够通过名称来查询IP 地址，或者通过IP 地址来查询名称，这样就能够在人和机器双方都不做出牺牲的前提下完美地解决问题。这个机制就是DNS

  如果要访问的Web 服务器已经在DNS 服务器上注册，那么这条记录就能够被找到，然后其IP 地址会被写入响应消息并返回给客户端（图1.12 ⑥）。 接下来，消息经过网络到达客户端，再经过协议栈被传递给解析器（图1.12 ⑦⑧）， 然后解析器读取出消息取出IP 地址，并将IP 地址传递给应用程序（图1.12 ⑨）。

### 26、打开一个url,发生了什么？
**（这个问题是重点！！！必问，这个可以给面试官说上一个小时的问题，推荐看一本书《网络是怎样连接的》）**

  浏览器首先要解析URL，从而生成发送给Web服务器的请求信息。解析完url后我们就知道应该访问的目标在哪里，然后浏览器会使用HTTP协议来访问Web服务器。此时说HTTP通信过程。（例如get：当服务器收到消息后，会打开文件并且读数据，将数据返回给客户端，最后客户端会收到这些数据并且显示在屏幕上）

  虽然浏览器能够解析网站，并且生成HTTP消息，但是他本身并不具备将消息发送到网络中的功能，在做这一步的时候还需要查询网址中服务器域名相对应的IP地址（因为IP地址比较难记，虽然也可以通过IP地址进行访问），此时就通过向DNS服务器发起查询。

  向DNS 服务器发出查询，也就是向DNS 服务器发送查询消息，并接收服务器返回的响应消息。换句话说，对于DNS 服务器，我们的计算机上一定有相应的DNS 客户端，而相当于DNS 客户端的部分称为DNS 解析器，或者简称解析器。通过DNS 查询IP 地址的操作称为域名解析，因此负责执行解析（resolution）这一操作的就叫解析器（resolver）了。
		
  知道了IP地址就可以通过socket进行发送数据，此时简历HTTP通信过程，通过请求报文相应报文进行分析，服务器分析请求报文，并且封装相应报文予以回复，浏览器解析相应报文，并把信息展示到浏览器上。
